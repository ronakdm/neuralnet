{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd5aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from optimizer import SteepestDescentOptimizer\n",
    "from nn import NeuralNetworkModule, NeuralNetworkClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516ff52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iter 00: 2.30\n",
      "Loss at iter 01: 1.83\n",
      "Loss at iter 02: 1.53\n",
      "Loss at iter 03: 1.34\n",
      "Loss at iter 04: 1.22\n",
      "Loss at iter 05: 1.14\n",
      "Loss at iter 06: 1.09\n",
      "Loss at iter 07: 1.06\n",
      "Loss at iter 08: 1.04\n",
      "Loss at iter 09: 1.02\n"
     ]
    }
   ],
   "source": [
    "# Test SteepestDescentOptimizer.\n",
    "\n",
    "def dummy_obj(x):\n",
    "    return np.dot(x, x) + 1\n",
    "\n",
    "def dummy_grad(x):\n",
    "    return 2 * x\n",
    "\n",
    "x = np.random.normal(size=(2,))\n",
    "optimizer = SteepestDescentOptimizer(1e-1)\n",
    "max_iter = 10\n",
    "\n",
    "for i in range(max_iter):\n",
    "    print(f\"Loss at iter {i:02}: {dummy_obj(x):0.2f}\")\n",
    "    x = optimizer.update(x, dummy_grad(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99ef122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  8.88178420e-16 -6.24500451e-17]\n",
      " [ 0.00000000e+00  8.88178420e-16 -6.24500451e-17]]\n"
     ]
    }
   ],
   "source": [
    "# Test NeuralNetworkModule.forward\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "nn1 = NeuralNetworkModule(dims=[2,3])\n",
    "W = nn1.parameters[\"weight_0\"]\n",
    "b = nn1.parameters[\"bias_0\"]\n",
    "\n",
    "x = np.ones((2, 2))\n",
    "\n",
    "z = (np.dot(W, x[0].reshape(-1, 1)) + b).reshape(1, -1)\n",
    "expected_scores = np.log(np.exp(z) / np.exp(z).sum()) # Numerically unstable, but fine for small example.\n",
    "expected_scores = np.repeat(expected_scores, 2, axis=0)\n",
    "scores = nn1.forward(x)\n",
    "\n",
    "print(scores - expected_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b08c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Test NeuralNetworkModule._compute_loss\n",
    "\n",
    "y = np.array([0, 2])\n",
    "\n",
    "expected_loss = -(scores[0, 0] + scores[1, 2]) # Negative log likelihood.\n",
    "loss = nn1._compute_loss(y, scores)\n",
    "\n",
    "print(loss - expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b86481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00000000e+00]\n",
      " [ 2.08166817e-17  2.08166817e-17]\n",
      " [-1.00000000e+00 -1.00000000e+00]]\n",
      "[[ 1.00000000e+00]\n",
      " [ 2.08166817e-17]\n",
      " [-1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Test NeuralNetworkModule.backward\n",
    "\n",
    "# x.shape = [batch_size * d_in]\n",
    "# W.shape = [n_classes * d_in]\n",
    "# z.shape = [batch_size * n_classes]\n",
    "\n",
    "expected_grad_W = np.zeros((3, 2))\n",
    "for i in [0, 1]:\n",
    "    expected_grad_W[0, i] = -x[0, i] + np.exp(z[0, 0]) / np.exp(z).sum() * x[0, i]\n",
    "    for j in [1, 2]:\n",
    "        expected_grad_W[j, i] = np.exp(z[0, j]) / np.exp(z).sum() * x[0, i]\n",
    "        \n",
    "expected_grad_b = np.zeros((3, 1))\n",
    "expected_grad_b[0] = -1 + np.exp(z[0, 0]) / np.exp(z).sum()\n",
    "for j in [1, 2]:\n",
    "    expected_grad_b[j] = np.exp(z[0, j]) / np.exp(z).sum()\n",
    "  \n",
    "nn1.backward(y, scores)\n",
    "grad_W = nn1.gradients[\"weight_0\"]\n",
    "grad_b = nn1.gradients[\"bias_0\"]\n",
    "\n",
    "print(grad_W - 2 * expected_grad_W)\n",
    "print(grad_b - 2 * expected_grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27999856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end test 1: Mixture of Gaussians.\n",
    "\n",
    "n = 100\n",
    "\n",
    "y_train = np.random.binomial(1, 0.5, size=n)\n",
    "X_train = np.random.normal(size=(n, 2)) + 10 * y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e774a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t | cross entropy loss: 20.5160 \t | train accuracy: 0.910\n",
      "Epoch 10 \t | cross entropy loss: 5.3498 \t | train accuracy: 1.000\n",
      "Epoch 20 \t | cross entropy loss: 2.9371 \t | train accuracy: 1.000\n",
      "Epoch 30 \t | cross entropy loss: 1.9673 \t | train accuracy: 1.000\n",
      "Epoch 40 \t | cross entropy loss: 1.5005 \t | train accuracy: 1.000\n",
      "Epoch 50 \t | cross entropy loss: 1.2502 \t | train accuracy: 1.000\n",
      "Epoch 60 \t | cross entropy loss: 1.0709 \t | train accuracy: 1.000\n",
      "Epoch 70 \t | cross entropy loss: 0.9041 \t | train accuracy: 1.000\n",
      "Epoch 80 \t | cross entropy loss: 0.7897 \t | train accuracy: 1.000\n",
      "Epoch 90 \t | cross entropy loss: 0.6989 \t | train accuracy: 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nn.NeuralNetworkClassifier at 0x7f80ac055100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "dims = [2, 2] \n",
    "init_scale = 1.0\n",
    "optimizer = SteepestDescentOptimizer(stepsize=1e-2)\n",
    "tol = 1e-8\n",
    "verbose = True\n",
    "\n",
    "nn = NeuralNetworkClassifier(\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    dims=dims,\n",
    "    init_scale=init_scale, \n",
    "    optimizer=optimizer,\n",
    "    tol=tol,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fcf5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end test 2: XOR.\n",
    "\n",
    "X_train = 10 * np.random.normal(size=(n, 2))\n",
    "y_train = (X_train[:, 0] * X_train[:, 1] >= 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e2cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t | cross entropy loss: 106.4657 \t | train accuracy: 0.710\n",
      "Epoch 100 \t | cross entropy loss: 61.2103 \t | train accuracy: 0.720\n",
      "Epoch 200 \t | cross entropy loss: 59.3535 \t | train accuracy: 0.740\n",
      "Epoch 300 \t | cross entropy loss: 77.9838 \t | train accuracy: 0.660\n",
      "Epoch 400 \t | cross entropy loss: 61.5183 \t | train accuracy: 0.760\n",
      "Epoch 500 \t | cross entropy loss: 66.5935 \t | train accuracy: 0.700\n",
      "Epoch 600 \t | cross entropy loss: 83.6706 \t | train accuracy: 0.770\n",
      "Epoch 700 \t | cross entropy loss: 69.3438 \t | train accuracy: 0.660\n",
      "Epoch 800 \t | cross entropy loss: 58.2789 \t | train accuracy: 0.720\n",
      "Epoch 900 \t | cross entropy loss: 61.7321 \t | train accuracy: 0.720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nn.NeuralNetworkClassifier at 0x7f80adaec430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 1000\n",
    "dims = [2, 2, 2] \n",
    "init_scale = 1.0\n",
    "optimizer = SteepestDescentOptimizer(stepsize=1e-2)\n",
    "tol = 1e-8\n",
    "verbose = True\n",
    "\n",
    "nn = NeuralNetworkClassifier(\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    dims=dims,\n",
    "    init_scale=init_scale, \n",
    "    optimizer=optimizer,\n",
    "    tol=tol,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb28b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
